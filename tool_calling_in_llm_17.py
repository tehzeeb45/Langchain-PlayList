# -*- coding: utf-8 -*-
"""tool-calling -in LLM_17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PG-wnkOg4PRNFTcruvnuOesJyNNW5bKp
"""

# Install required packages
!pip install -q langchain langchain-community transformers torch

from langchain_community.llms import HuggingFacePipeline
from transformers import pipeline
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage
import requests

# Example: using a Hugging Face model (free)
generator = pipeline(
     "text2text-generation",
            model="google/flan-t5-xl",
            max_new_tokens=300,
            temperature=0.3
)
# Wrap in LangChain
llm = HuggingFacePipeline(pipeline=generator)

# tool Create
@tool
def multiply(a: int, b:int) -> int:
  """Given 2 number a and b this tool returns their product"""
  return a*b

print(multiply.invoke({'a':3, 'b' :4}))

multiply.name
multiply.args

# tool Binding
llm_with_tool = llm.bind_tools([multiply])

reuslt = llm_with_tool.invoke("can you multiply 3 with 10").tool_calls[0]

result.tool_call[0]

multiply.invoke(result.tool_calls[0])

